{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "sns.set_style(\"whitegrid\");\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pickle as pkl\n",
    "import tqdm as tqdm\n",
    "from random import choices\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_dataframe(df):\n",
    "    '''\n",
    "    one hot encoding \n",
    "    '''\n",
    "    original_columns = list(df.columns)\n",
    "    cat_columns=[x for x in df.columns if df[x].dtype == 'object']\n",
    "    df=pd.get_dummies(df,columns=cat_columns,dummy_na= False)\n",
    "    new_added_columns=list(set(df.columns).difference(set(original_columns)))\n",
    "    return df,new_added_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_on_app_train_test(test_point):\n",
    "    \n",
    "    '''\n",
    "    final feature engineering applied on app_train and app_test\n",
    "    \n",
    "    '''\n",
    "#     app_train=pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\n",
    "#     app_test=pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')\n",
    "#     #we merge the two data frames the preprocessing we on train must also be done on test\n",
    "#     df=app_train.append(app_test).reset_index()\n",
    "    \n",
    "#     del app_train\n",
    "#     del app_test\n",
    "    \n",
    "#     df=df[df['CODE_GENDER']!='XNA'] \n",
    "\n",
    "    df=test_point\n",
    "    \n",
    "#     print(df.head())\n",
    "    \n",
    "#     df[\"CODE_GENDER\"].replace({'XNA': np.nan}, inplace = True)\n",
    "    \n",
    "#     df[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n",
    "    \n",
    "    \n",
    "    with open(\"all_columns_app_train_test.pkl\", \"rb\") as f:\n",
    "        all_columns = pkl.load(f)\n",
    "    \n",
    "#     print(df.head())\n",
    "    \n",
    "    \n",
    "#     with open(\"all_columns_app_train_test.pkl\", \"wb\") as f:\n",
    "#         pkl.dump(all_columns, f)\n",
    "    \n",
    "#     df=df[df['SK_ID_CURR']==id_value]\n",
    "\n",
    "#     #The XNA value doesn't mean any thing so it is removed from train data\n",
    "#     df=df[df['CODE_GENDER']!='XNA'] \n",
    "        \n",
    "#     #we remove this because 365243 is an outlier\n",
    "\n",
    "\n",
    "#     #There is an outlier in the train data where AMT_INCOME_TOTAL of a person having highest income had difficulty in paying loan. \n",
    "#     df=df[df['AMT_INCOME_TOTAL']<(0.2*1e8)]\n",
    " \n",
    "#     print(list(df.columns))\n",
    "    \n",
    "    df['DOCUMNNET_COUNT']=(df[['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "       'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
    "       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n",
    "       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']]==1).sum(axis=1)\n",
    "    \n",
    "    \n",
    "    df['AMT_REQ_CREDIT_BUREAU_HDWMQY']=(df[['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "       'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "       'AMT_REQ_CREDIT_BUREAU_YEAR']]).sum(axis=1)\n",
    "    \n",
    "    \n",
    "    #Using domain knowledge and Pairplot\n",
    "    \n",
    "#     df['AMT_CREDIT_FLAG']=( df['AMT_CREDIT']<=300000).astype(int)\n",
    "    \n",
    "#     df['DAYS_BIRTH_FLAG']=(abs(df['DAYS_BIRTH']//365)<=19).astype(int)\n",
    "    \n",
    "    #pecentage of his life spent working\n",
    "    df['DAYS_WORKING_PER']=df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    \n",
    "    df['DAYS_UNEMPLOYED']=abs(df['DAYS_BIRTH'])-abs(df['DAYS_EMPLOYED'])\n",
    "    \n",
    "    df['GOODS_PRICE_INCOME_TOTAL_PER']=df['AMT_INCOME_TOTAL']/df['AMT_GOODS_PRICE']\n",
    "    \n",
    "    df['GOODS_PRICE_CREDIT_PER']=df['AMT_CREDIT']/df['AMT_GOODS_PRICE']\n",
    "    \n",
    "    df['GOODS_PRICE_AMT_ANNUITY_PER']=df['AMT_ANNUITY']/df['AMT_GOODS_PRICE']\n",
    "    \n",
    "#     df['GOODS_PRICE_EMP']=abs(df['DAYS_EMPLOYED'])/df['AMT_GOODS_PRICE']\n",
    "    \n",
    "#     df['AMT_CREDIT_BIRTH']=df['AMT_CREDIT']/abs(df['DAYS_BIRTH']/365)\n",
    "    \n",
    "    #percentage income of person and the credit amount\n",
    "    df['INCOME_CREDIT_PER'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "\n",
    "    #percentage income of person and the credit amount\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / (df['CNT_FAM_MEMBERS']+1)\n",
    "\n",
    "    #Amount paid for previous loan application every month decided by the number of day employed\n",
    "    df['ANNUITY_DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED']/ df['AMT_ANNUITY']\n",
    "    \n",
    "    df['AMT_CREDIT_DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED']/ df['AMT_CREDIT']\n",
    "    \n",
    "    #Amount paid for  loan application every month decided by the number of day lived\n",
    "    df['ANNUITY_DAYS_BIRTH_PERC'] = df['DAYS_BIRTH']/ df['AMT_ANNUITY']\n",
    "\n",
    "    #Anually paid amount to amount credited\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    \n",
    "    df['PAYMENT_RATE_INV'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "\n",
    "    df['PAY_TOWARDS_LOAN'] = df['AMT_INCOME_TOTAL']-df['AMT_ANNUITY']\n",
    "\n",
    "    # df['AMT_INCOME_TOTAL_FLAG_LOAN_LESS_50'] =(df['AMT_ANNUITY']<=(0.50*df['AMT_INCOME_TOTAL'])).astype(int)\n",
    "    \n",
    "    df['MEAN_DEFAULT_SURR']=((df[['OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "       'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']]).sum(axis=1))//4\n",
    "    \n",
    "    df['ADDRESS_MISSMATCH']=((df[['REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
    "       'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY','LIVE_CITY_NOT_WORK_CITY']]).sum(axis=1))\n",
    "    \n",
    "    df['MEAN_ENQUIRIES']=((df[['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "       'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']]).mean(axis=1))\n",
    "    \n",
    "    df['CONTACT_REF']=((df[['FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
    "       'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE','FLAG_PHONE','FLAG_EMAIL']]).sum(axis=1))\n",
    "    \n",
    "    df['MAX_DAYS_SOMETHING_CHANGED']=((df[['DAYS_EMPLOYED', 'DAYS_ID_PUBLISH',\n",
    "       'DAYS_REGISTRATION']]).max(axis=1))\n",
    "    \n",
    "    #Creating features from useful features\n",
    "    df['EXT_SOURCE_MEAN']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
    "       'EXT_SOURCE_3']]).mean(axis=1)\n",
    "    \n",
    "    df['EXT_SOURCE_MEDIAN']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
    "       'EXT_SOURCE_3']]).median(axis=1)\n",
    "    \n",
    "    df['EXT_SOURCE_MIN']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
    "       'EXT_SOURCE_3']]).min(axis=1)\n",
    "    \n",
    "    df['EXT_SOURCE_MAX']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
    "       'EXT_SOURCE_3']]).max(axis=1)\n",
    "    \n",
    "    \n",
    "    df,new_cat_columns=one_hot_encoding_dataframe(df)\n",
    "    add_columns=list(set(all_columns)-set(df.columns))\n",
    "    for col in add_columns:\n",
    "        df[col]=0\n",
    "    df['TARGET']=np.nan    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_the_missing_values(df):\n",
    "    \n",
    "    with open(\"missing_3_list_7.pkl\", \"rb\") as f:\n",
    "        missing_3_list = pkl.load(f)\n",
    "    with open(\"missing_2_list (1).pkl\", \"rb\") as f:\n",
    "        missing_2_list = pkl.load(f)\n",
    "    with open(\"missing_1_list_7.pkl\", \"rb\") as f:\n",
    "        missing_1_list = pkl.load(f)\n",
    "    with open(\"ridge_clf_list (3).pkl\", \"rb\") as f:\n",
    "        ridge_clf_list = pkl.load(f)\n",
    "    with open(\"ridge_train_column_list (1).pkl\", \"rb\") as f:\n",
    "        ridge_train_column_list = pkl.load(f)\n",
    "        \n",
    "    imputer1 = pkl.load(open('imputer1_7.sav', 'rb'))\n",
    "    \n",
    "    present_list = pkl.load(open('median_present_list (1).pkl', 'rb'))\n",
    "      \n",
    "    df.replace([np.inf, -np.inf], np.nan,inplace=True)    \n",
    "    \n",
    "    df=df.drop(columns=missing_3_list).copy()    \n",
    "\n",
    "    mean_imp_test_data  = imputer1.transform(df[missing_1_list])\n",
    "    \n",
    "    df.loc[:,missing_1_list]=mean_imp_test_data.copy()\n",
    "\n",
    "    temp_list=[]\n",
    "    for i in range(0,len(missing_2_list)):\n",
    "        if df[missing_2_list[i]].isnull().bool():\n",
    "            df[\"temp_\"+str(missing_2_list[i])]=present_list[i]\n",
    "        else:\n",
    "            df[\"temp_\"+str(missing_2_list[i])]=df[missing_2_list[i]]   \n",
    "        temp_list.append(\"temp_\"+missing_2_list[i]) \n",
    "    \n",
    "    for i in range(0,len(missing_2_list)):\n",
    "        train_columns=ridge_train_column_list[i]\n",
    "        if df[missing_2_list[i]].isnull().bool():\n",
    "            df[missing_2_list[i]] = ridge_clf_list[i].predict(df[train_columns]) \n",
    "    df.drop(columns=temp_list,inplace=True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cibil_score(df):\n",
    "    cibil_test=df[['3365_LATE_PAYMENT_FLAG_MEAN','CRED_FLAG_LESS_30_MEAN','ABS_YEAR_CREDIT_MAX','UNSEC_LOAN_COUNT_SUM','SEC_LOAN_COUNT_SUM','AMT_REQ_CREDIT_BUREAU_WEEK']].copy()    \n",
    "    \n",
    "    scaler_cibil = pkl.load(open('scaler_cibil_7.sav', 'rb'))\n",
    "    \n",
    "    cibil_test_std = scaler_cibil.transform(cibil_test)\n",
    "    \n",
    "    cibil_test = pd.DataFrame(data = cibil_test_std,  \n",
    "                      columns = ['3365_LATE_PAYMENT_FLAG_MEAN','CRED_FLAG_LESS_30_MEAN','ABS_YEAR_CREDIT_MAX','UNSEC_LOAN_COUNT_SUM','SEC_LOAN_COUNT_SUM','AMT_REQ_CREDIT_BUREAU_WEEK']) \n",
    "    \n",
    "    num_test=(0.1*cibil_test['UNSEC_LOAN_COUNT_SUM'].copy()+0.1*cibil_test['SEC_LOAN_COUNT_SUM'].copy()+0.05*cibil_test['ABS_YEAR_CREDIT_MAX'].copy()+0.25*cibil_test['CRED_FLAG_LESS_30_MEAN'].copy())\n",
    "    \n",
    "    den_test=(0.30*cibil_test['3365_LATE_PAYMENT_FLAG_MEAN'].copy()+0.20*cibil_test['AMT_REQ_CREDIT_BUREAU_WEEK'].copy())+1\n",
    "    \n",
    "    df.loc[:,'CIBIL_SCORE']=(num_test.copy()/den_test.copy())\n",
    "    \n",
    "    df.loc[:,'CIBIL_SCORE']=df['CIBIL_SCORE'].fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main1(test_point):\n",
    "    df=feature_engineering_on_app_train_test(test_point)\n",
    "    with open(\"df_test.pkl\", \"rb\") as f:\n",
    "        df_past = pkl.load(f)\n",
    "    with open(\"lgbm_clf_list_7.pkl\", \"rb\") as f:\n",
    "        lgbm_list = pkl.load(f)   \n",
    "    with open(\"train_column7.pkl\", \"rb\") as f:\n",
    "        train_column = pkl.load(f)\n",
    "    with open(\"scaler_7.sav\", \"rb\") as f:\n",
    "        scaler = pkl.load(f)\n",
    "    df_past['SK_ID_CURR']=df_past.index\n",
    "    test_point_past_data=df_past[df_past['SK_ID_CURR']==int(test_point['SK_ID_CURR'].values)]\n",
    "    test_point_past_data.drop('SK_ID_CURR',axis=1,inplace=True)\n",
    "    df=df.join(test_point_past_data,how='left', on='SK_ID_CURR')\n",
    "    del df_past\n",
    "    gc.collect()\n",
    "    df=fill_the_missing_values(df)\n",
    "    df=calculate_cibil_score(df)\n",
    "    X=df[train_column]\n",
    "    X_scaled=scaler.transform(X)\n",
    "    test_pred_proba=0\n",
    "    for j in range(0,len(lgbm_list)):\n",
    "        test_pred_proba+=lgbm_list[j].predict_proba(X_scaled,num_iteration=lgbm_list[j].best_iteration_)[:,1]/10\n",
    "    print('ID: ',df['SK_ID_CURR'].values,'Prediction: ',int(test_pred_proba>0.5),'Prediction Probablility: ',test_pred_proba)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2(test_points,y_train):\n",
    "    datatype_columns={}\n",
    "    for x in test_points.columns:\n",
    "        datatype_columns[x]=test_points[x].dtype\n",
    "    y_predict=[]\n",
    "    for i in range(0,len(test_points)):\n",
    "        test_point=pd.DataFrame(test_points.values[i].reshape(1,-1),columns=list(test_points.iloc[i].index))\n",
    "        test_point = test_point.astype(datatype_columns)\n",
    "        df=feature_engineering_on_app_train_test(test_point)\n",
    "        with open(\"df_test.pkl\", \"rb\") as f:\n",
    "            df_past = pkl.load(f)\n",
    "        with open(\"lgbm_clf_list_7.pkl\", \"rb\") as f:\n",
    "            lgbm_list = pkl.load(f)   \n",
    "        with open(\"train_column7.pkl\", \"rb\") as f:\n",
    "            train_column = pkl.load(f)\n",
    "        with open(\"scaler_7.sav\", \"rb\") as f:\n",
    "            scaler = pkl.load(f)\n",
    "        df_past['SK_ID_CURR']=df_past.index\n",
    "        test_point_past_data=df_past[df_past['SK_ID_CURR']==int(test_point['SK_ID_CURR'].values)]\n",
    "        test_point_past_data.drop('SK_ID_CURR',axis=1,inplace=True)\n",
    "        df=df.join(test_point_past_data,how='left', on='SK_ID_CURR')\n",
    "        del df_past\n",
    "        gc.collect()\n",
    "        df=fill_the_missing_values(df)\n",
    "        df=calculate_cibil_score(df)\n",
    "        X=df[train_column]\n",
    "        X=scaler.transform(X)\n",
    "        test_pred_proba=0\n",
    "        for j in range(0,len(lgbm_list)):\n",
    "             test_pred_proba+=lgbm_list[j].predict_proba(X,num_iteration=lgbm_list[j].best_iteration_)[:, 1]/10\n",
    "        print('ID:',df['SK_ID_CURR'].values,'Prediction:',int(test_pred_proba>0.5),'Prediction Probablility:',test_pred_proba,'y_actual: ',y_train.iloc[i])  \n",
    "        y_predict.append(test_pred_proba)\n",
    "    print('ROC-AUC score',roc_auc_score(y_train,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train=pd.read_csv('application_train.csv')\n",
    "app_test=pd.read_csv('application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                0                0                0                0   \n",
       "1  ...                0                0                0                0   \n",
       "2  ...                0                0                0                0   \n",
       "3  ...                0                0                0                0   \n",
       "4  ...                0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         0.0  \n",
       "1                        0.0                         3.0  \n",
       "2                        1.0                         4.0  \n",
       "3                        0.0                         3.0  \n",
       "4                        NaN                         NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point=app_test.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  [100001] Prediction:  0 Prediction Probablility:  [0.034699]\n"
     ]
    }
   ],
   "source": [
    "main1(test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_points=app_train.sample(80)\n",
    "train_points\n",
    "y=train_points['TARGET']\n",
    "X_train=train_points.drop('TARGET',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: [340121] Prediction: 0 Prediction Probablility: [0.17251587] y_actual:  0\n",
      "ID: [238870] Prediction: 0 Prediction Probablility: [0.07623851] y_actual:  0\n",
      "ID: [445290] Prediction: 0 Prediction Probablility: [0.01293887] y_actual:  0\n",
      "ID: [436999] Prediction: 0 Prediction Probablility: [0.02155605] y_actual:  0\n",
      "ID: [362325] Prediction: 0 Prediction Probablility: [0.01248308] y_actual:  0\n",
      "ID: [377861] Prediction: 0 Prediction Probablility: [0.02249652] y_actual:  0\n",
      "ID: [454060] Prediction: 0 Prediction Probablility: [0.13889779] y_actual:  1\n",
      "ID: [294906] Prediction: 0 Prediction Probablility: [0.02564005] y_actual:  0\n",
      "ID: [319469] Prediction: 0 Prediction Probablility: [0.01655263] y_actual:  0\n",
      "ID: [349319] Prediction: 0 Prediction Probablility: [0.05786691] y_actual:  0\n",
      "ID: [101927] Prediction: 0 Prediction Probablility: [0.0133861] y_actual:  0\n",
      "ID: [260511] Prediction: 0 Prediction Probablility: [0.05819658] y_actual:  0\n",
      "ID: [102696] Prediction: 0 Prediction Probablility: [0.10875774] y_actual:  0\n",
      "ID: [241122] Prediction: 0 Prediction Probablility: [0.03411915] y_actual:  0\n",
      "ID: [445973] Prediction: 0 Prediction Probablility: [0.2460465] y_actual:  0\n",
      "ID: [405360] Prediction: 0 Prediction Probablility: [0.00888801] y_actual:  0\n",
      "ID: [436073] Prediction: 0 Prediction Probablility: [0.05032694] y_actual:  0\n",
      "ID: [368110] Prediction: 0 Prediction Probablility: [0.16095327] y_actual:  0\n",
      "ID: [456152] Prediction: 0 Prediction Probablility: [0.02642218] y_actual:  0\n",
      "ID: [155621] Prediction: 0 Prediction Probablility: [0.07010119] y_actual:  0\n",
      "ID: [212181] Prediction: 0 Prediction Probablility: [0.10582772] y_actual:  0\n",
      "ID: [305687] Prediction: 0 Prediction Probablility: [0.02644908] y_actual:  0\n",
      "ID: [318386] Prediction: 0 Prediction Probablility: [0.05895684] y_actual:  0\n",
      "ID: [200110] Prediction: 0 Prediction Probablility: [0.01747602] y_actual:  0\n",
      "ID: [215151] Prediction: 0 Prediction Probablility: [0.06088602] y_actual:  0\n",
      "ID: [430686] Prediction: 0 Prediction Probablility: [0.36887896] y_actual:  0\n",
      "ID: [327387] Prediction: 0 Prediction Probablility: [0.0162016] y_actual:  0\n",
      "ID: [149640] Prediction: 0 Prediction Probablility: [0.02952641] y_actual:  0\n",
      "ID: [181181] Prediction: 0 Prediction Probablility: [0.06209492] y_actual:  0\n",
      "ID: [307817] Prediction: 0 Prediction Probablility: [0.10159061] y_actual:  0\n",
      "ID: [116760] Prediction: 0 Prediction Probablility: [0.07055312] y_actual:  0\n",
      "ID: [272437] Prediction: 0 Prediction Probablility: [0.22902331] y_actual:  1\n",
      "ID: [333873] Prediction: 0 Prediction Probablility: [0.06783046] y_actual:  0\n",
      "ID: [110680] Prediction: 0 Prediction Probablility: [0.03395098] y_actual:  0\n",
      "ID: [263324] Prediction: 0 Prediction Probablility: [0.04856479] y_actual:  0\n",
      "ID: [133751] Prediction: 0 Prediction Probablility: [0.06434846] y_actual:  0\n",
      "ID: [196031] Prediction: 0 Prediction Probablility: [0.1064347] y_actual:  0\n",
      "ID: [384853] Prediction: 0 Prediction Probablility: [0.02500423] y_actual:  0\n",
      "ID: [269353] Prediction: 0 Prediction Probablility: [0.41705368] y_actual:  1\n",
      "ID: [276414] Prediction: 0 Prediction Probablility: [0.08508028] y_actual:  0\n",
      "ID: [166324] Prediction: 0 Prediction Probablility: [0.01517263] y_actual:  0\n",
      "ID: [390289] Prediction: 0 Prediction Probablility: [0.09788388] y_actual:  0\n",
      "ID: [141328] Prediction: 0 Prediction Probablility: [0.08971487] y_actual:  0\n",
      "ID: [107896] Prediction: 0 Prediction Probablility: [0.0596045] y_actual:  0\n",
      "ID: [367072] Prediction: 0 Prediction Probablility: [0.01941727] y_actual:  0\n",
      "ID: [370039] Prediction: 0 Prediction Probablility: [0.06693356] y_actual:  0\n",
      "ID: [178701] Prediction: 0 Prediction Probablility: [0.05764114] y_actual:  0\n",
      "ID: [344230] Prediction: 0 Prediction Probablility: [0.03506888] y_actual:  0\n",
      "ID: [317999] Prediction: 0 Prediction Probablility: [0.2748981] y_actual:  0\n",
      "ID: [210944] Prediction: 0 Prediction Probablility: [0.11437249] y_actual:  0\n",
      "ID: [147529] Prediction: 0 Prediction Probablility: [0.05785419] y_actual:  0\n",
      "ID: [315482] Prediction: 0 Prediction Probablility: [0.16851585] y_actual:  1\n",
      "ID: [105186] Prediction: 0 Prediction Probablility: [0.03660019] y_actual:  0\n",
      "ID: [221896] Prediction: 0 Prediction Probablility: [0.1367231] y_actual:  1\n",
      "ID: [287560] Prediction: 0 Prediction Probablility: [0.05428738] y_actual:  0\n",
      "ID: [342505] Prediction: 0 Prediction Probablility: [0.08442185] y_actual:  0\n",
      "ID: [102253] Prediction: 0 Prediction Probablility: [0.08990079] y_actual:  0\n",
      "ID: [253597] Prediction: 0 Prediction Probablility: [0.07389114] y_actual:  0\n",
      "ID: [206014] Prediction: 0 Prediction Probablility: [0.113624] y_actual:  0\n",
      "ID: [323323] Prediction: 0 Prediction Probablility: [0.09302913] y_actual:  0\n",
      "ID: [360284] Prediction: 0 Prediction Probablility: [0.10260153] y_actual:  0\n",
      "ID: [359670] Prediction: 0 Prediction Probablility: [0.0185134] y_actual:  0\n",
      "ID: [427583] Prediction: 0 Prediction Probablility: [0.26225967] y_actual:  0\n",
      "ID: [123904] Prediction: 0 Prediction Probablility: [0.03613255] y_actual:  0\n",
      "ID: [199614] Prediction: 0 Prediction Probablility: [0.01850273] y_actual:  0\n",
      "ID: [380300] Prediction: 0 Prediction Probablility: [0.10928155] y_actual:  0\n",
      "ID: [376389] Prediction: 0 Prediction Probablility: [0.02192742] y_actual:  0\n",
      "ID: [203873] Prediction: 0 Prediction Probablility: [0.05193537] y_actual:  0\n",
      "ID: [337213] Prediction: 0 Prediction Probablility: [0.06690906] y_actual:  0\n",
      "ID: [308071] Prediction: 0 Prediction Probablility: [0.07992963] y_actual:  0\n",
      "ID: [272668] Prediction: 0 Prediction Probablility: [0.02961424] y_actual:  0\n",
      "ID: [295308] Prediction: 0 Prediction Probablility: [0.06595543] y_actual:  1\n",
      "ID: [169998] Prediction: 0 Prediction Probablility: [0.09099519] y_actual:  0\n",
      "ID: [144669] Prediction: 0 Prediction Probablility: [0.08069999] y_actual:  0\n",
      "ID: [169281] Prediction: 0 Prediction Probablility: [0.10022255] y_actual:  0\n",
      "ID: [353379] Prediction: 0 Prediction Probablility: [0.05022386] y_actual:  0\n",
      "ID: [246702] Prediction: 0 Prediction Probablility: [0.02230382] y_actual:  0\n",
      "ID: [434540] Prediction: 0 Prediction Probablility: [0.09334605] y_actual:  0\n",
      "ID: [147888] Prediction: 0 Prediction Probablility: [0.0250695] y_actual:  0\n",
      "ID: [163912] Prediction: 0 Prediction Probablility: [0.08042462] y_actual:  0\n",
      "ROC-AUC score 0.8783783783783784\n"
     ]
    }
   ],
   "source": [
    "main2(X_train,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
